---
title: "WQD7004 OCC3 Group 5"
author: |
  LOO LING YAN (23904683)
  
  XIAN ZHIYI (23126222)
  
  WONG YI TING (52152880)
  
  CHU JING HAN (23124693)
  
  HAU JIA QI (17204762)
date: "2025-01-04"
output:
  html_document:
    warning: false
  pdf_document: default
---

This R Markdown document is the complete report of the group project by Group 5 for Occurrence 3 of the WQD7004 course in Faculty of Computer Science and Information Technology, University of Malaya for Semester 1 of 2024/2025 Academic Session.

---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning=FALSE)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
  dplyr,
  modeest,
  caret,
  rpart,
  randomForest,
  xgboost,
  e1071,
  ggplot2,
  readr
)
```
## **1. Introduction**

**Title: ** Forecasting Market Sales by Using Machine Learning

This project aims to predict supermarket sales trends, identify the key factors influencing sales, and classify customer types (Normal or Member) using supervised machine learning techniques. The dataset is sourced from Kaggle and contains transaction records, customer demographics, and product details.

The analysis focuses on:

+ Data Preprocessing: Handling missing values, standardizing data formats, and removing inconsistencies.
+ Exploratory Data Analysis (EDA): Understanding data distribution, patterns, and relationships between variables.
+ Regression Modeling: Predicting total sales amount per transaction using Linear Regression, Random Forest, and Gradient Boosting Regression models.
+ Classification Modeling: Classifying customer types (Member vs. Normal) using Random Forest, Decision Tree, KNN, XGBoost, and LightGBM models.
+ Model Evaluation: Comparing model performances using evaluation metrics such as Accuracy, F1-Score, R² Score, and Mean Squared Error (MSE).
+ Insights and Recommendations: Drawing actionable conclusions for business decision-makers based on model outcomes.


Through this analysis, we aim to deliver an effective predictive framework that supports data-driven strategies for sales optimization and customer segmentation.

**Goal:**
To predict sales trends and classify customer types (Normal or Member) using supervised machine learning models.

**Objectives:**  

+ To classify customer types (Normal or Member) using supervised classification models.
+ To predict the total sales amount of individual transactions using regression models.
+ To compare and identify the best-performing model for both regression and classification tasks.
+ To evaluate model performance using key metric.

**Research Questions:**  

+ Which machine learning model provides the most accurate sales predictions?
+ What are the key factors influencing supermarket sales trends?
+ Which classification model (Random Forest, KNN, Decision Tree, XGBoost, LightGBM) performs best for predicting customer types?


**Dataset description:**  

+ Title: Market Sales Data
+ Year: 2024
+ Source:[https://www.kaggle.com/datasets/willianoliveiragibin/market-sales-data/data](https://www.kaggle.com/datasets/willianoliveiragibin/market-sales-data/data)  
+ Purpose: Analyze supermarket sales trends and forecast future sales.
+ Dimension: 1000 rows × 9 columns
+ Structure: The structured tabular dataset contains numerical and categorical data.
+ Summary: This dataset provides detailed transaction data from a supermarket, capturing customer demographics, product preferences, purchasing quantities, and sales-related financial details.

---

## **2. Data Preprocessing **

### **2.1 Load libraries and functions**
```r
install.packages("dplyr")
install.packages("modeest")
install.packages("caret")
install.packages("ggplot2")
install.packages("readr")
library(caret)
library(dplyr)
library(readr)
library(modeest)
library(readr)
```

### **2.2 General Overview of The Raw Dataset**
**Import raw data**
```{r warning=FALSE,echo=TRUE}
# Import raw data
df <- read_csv("supermarket_sales.csv", show_col_types = FALSE)
glimpse(df)
```
**The dataset details:**

###### - **Gender:** Customer gender (Male/Female)

###### - **Invoice ID:** Unique transaction identifier

###### - **Branch:** Store branch identifier

###### - **City:** City where the branch is located

###### - **Customer Type:** Membership status (Member/Normal)

###### - **Product Line:** Category of purchased product

###### - **Unit Price:** Price per unit of the product

###### - **Quantity:** Number of units purchased

###### - **Tax 5%:** Tax calculated based on sales


### **2.3 Data Cleaning**

##### **Rename the columns as the column name contains spacing**

```{r }
df <- setNames(df, c("Gender", "Invoice_ID", "Branch","City", "Customer_type", "Product_line", "Unit_price", "Quantity", "Tax_5pct"))
head(df)
```

##### **Check duplication from dataset**

```{r}
dup <- sum(duplicated(df))
cat("Total duplicated from supermarket_sales is", dup)
```
+ Result: no duplication here.


##### **Drop invoice ID that no related to the analysis**
```{r}
df<-df %>% select(-Invoice_ID)
```

##### **Run glimpse again to ensure Invoice ID was drop from the dataset**
```{r}
glimpse(df)
```
+ Result: Invoice_ID is remove from the dataset.

##### **Check missing value from any columns**
```{r}
any(is.na(df))
```
+ Result: Existing dataset having missing value.

##### **Check numbers for row without missing value**
```{r}
nrow(na.omit(df))
```

##### **Check the missing value record**
```{r}
nrow(df[!complete.cases(df),])
```
+ Result: Total 1000 records show 994 records is complete record and 6 records having missing value.

##### **Check which column having missing value**
```{r}
check_column_missing <-names(df)
for(i in check_column_missing ) {
print(paste(i, sum(df[i]=="" | is.na(df[i]))))
}
```
+ Result: "Produt line" and "unit price" having missing value.


##### **Check which column having NA**
```{r}
check_column_missing <-names(df)
for(i in check_column_missing ) {
print(paste(i, sum(is.na(df[i]))))
}
```
+ Result: Using others command to check the NA also show the same result.


##### **Check which column having missing value**
```{r}
for(i in check_column_missing) {
print(paste(i, which(df[i]=="" | is.na(df[i]))))
}
```
+ Result: missing value for "Product line 39" "Product line 76" "Product line 117" and also "Unit price 57" "Unit price 82" "Unit price 103".
+ There are 6 rows of missing value in the dataset. To fill in the missing value, mode method is used for the column 'Product Line' and calculation to fill in the missing value for column 'Tax_5%'.

```{r}
Prod_mode <- function(x) {
  uniq_x <- unique(x)
  uniq_x[which.max(tabulate(match(x, uniq_x)))]
}
mode_pro <- Prod_mode(df$Product_line)
print(mode_pro)
```


##### **Fill in the "Fashion accessorie" to the missing value from the Product line.**
```{r}
df <- df %>% mutate(Product_line = ifelse(is.na(Product_line), "Fashion accessories", Product_line))
# Check the missing value had fill with "Fashion accessories"
df[39, ]
```
+ Result: "Product_line 39" was fill in with "Fashion accessories".


##### **Check missing value row again**
```{r}
nrow(na.omit(df))
```
+ Result: the non-missing value was increase from 994 records to 997 records.


##### **Get mean value by removing missing value**
```{r}
mean_unit_price <- round(mean(df$Unit_price, na.rm=T), 2)
mean_unit_price

# fill in the mean value=55.8 to the missing value of unit_price
df <- df %>% mutate(Unit_price = ifelse(is.na(Unit_price), 55.8, Unit_price))

# check the "Unit_price 82" that fill in 55.8
df[82, ]
```
+ Result: the unit_price was fill in the mean value.


##### **Check the missing record from the dataset again**
```{r}
nrow(na.omit(df))

```
+ Result: Now, all the missing value was filled in.


##### **Check the amount of tax= unit price * quantity * tax 5%**
```{r}
df <- df %>% mutate(Tax= Unit_price * Quantity * 0.05)
df<-df %>% select(-Tax_5pct)
head(df)
```
+ Result: rom eyeboll checking the "Tax 5%" is different with "total_sales". Therefore, "Tax 5%" will drop from the dataset.


##### **Check complete records for each rows**
```{r}
sum(complete.cases(df))

# Detect outlier from the Tax
Q1 <- quantile(df$Tax, 0.25)
Q3 <- quantile(df$Tax, 0.75)
IQR <- Q3 - Q1

# Define the lower and upper bounds
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR

# Remove outliers
df<- df[df$Tax >= lower_bound & df$Tax <= upper_bound, ]

# check numbers of records
nrow(df)

# summary of dataset
summary(df)
 
# Cleaning of dataset
head(df)

```
+ Result: now, the data is clean after removing the outlier and using for the following analysis.

---

## **3. EDA**

### **3.1 Gender Distribution**
```{r}
# Generate frequency table
gender_counts <- table(df$Gender)
# Convert to a data frame
gender_df <- as.data.frame(gender_counts)
colnames(gender_df) <- c("Gender", "Count")
#Plot pie chart
ggplot(gender_df, aes(x = "", y = Count, fill = Gender)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Gender Distribution") +
  theme_void()
```

### **3.2 Membership Distribution**
```{r}
# Generate frequency table
member <- table(df$Customer_type)
# Convert to a data frame
memberdf <- as.data.frame(member)
colnames(memberdf) <- c("Member", "Count")
#Plot pie chart
ggplot(memberdf, aes(x = "", y = Count, fill = Member)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Membership Distribution") +
  theme_void()
```

### **3.3 Proportion of Membership by Gender**
```{r}
memgen <- df %>%
  group_by(Customer_type, Gender) %>%
  tally() %>%
  group_by(Customer_type) %>%
  mutate(Proportion = n / sum(n))

# Stacked bar chart for the proportion of membership by gender
ggplot(memgen, aes(x = Customer_type, y = Proportion, fill = Gender)) +
  geom_bar(stat = "identity") +
  labs(title = "Proportion of Membership by Gender", x = "Membership", y = "Proportion") +
  scale_y_continuous(labels = scales::percent)
```

### **3.4 Total Unit Sold for Each Product**
```{r}
total <- df %>%
  group_by(Product_line) %>%
  summarize(totalunit = sum(Quantity))

# Bar chart of Total Units Sold by Product Line
ggplot(total, aes(x = Product_line, y = totalunit, fill = Product_line)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(title = "Total Units Sold by Product Line",
       x = "Product Line",
       y = "Total Units Sold") +
  theme_minimal()
```

### **3.5 Analyze sales distribution and trends by city**
```{r}
citysales <- df %>% group_by(City) %>%
  summarize(totalsales = sum(Quantity)) %>%
  arrange(desc(totalsales))
ggplot(citysales, aes(x = reorder(City, -totalsales), y = totalsales, fill = City)) +
  geom_bar(stat = "identity") +
  labs(title = "Sales Distribution by City", x = "City", y = "Total Sales")
```

### **3.6 Analyze sales distribution and trends by branch**
```{r}
branchsales <- df %>% group_by(Branch) %>%
  summarize(totalbranchsales = sum(Quantity)) %>%
  arrange(desc(totalbranchsales))
ggplot(branchsales, aes(x = reorder(Branch, -totalbranchsales), y = totalbranchsales, fill = Branch)) +
  geom_bar(stat = "identity") +
  labs(title = "Sales Distribution by Branch", x = "Branch", y = "Total Sales")
```

### **3.7 Analyze sales distribution and trends by product line**
```{r}
productsales <- df %>% group_by(Product_line) %>%
  summarize(totalproductsales = sum(Quantity)) %>%
  arrange(desc(totalproductsales))
ggplot(productsales, aes(x = reorder(Product_line, -totalproductsales), y = totalproductsales, fill = Product_line)) +
  geom_bar(stat = "identity") +
  labs(title = "Sales Distribution by Product Line", x = "Product Line", y = "Total Sales")
```

### **3.8 Analyze sales of product line in each city**
```{r}
sales_summary <- df %>%
  group_by(City, Branch, Product_line) %>%
  summarize(Total_Sales = sum(Quantity, na.rm = TRUE))

ggplot(sales_summary, aes(x = City, y = Total_Sales, fill = Product_line)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Sales Distribution by Product Line and City",
       x = "City", y = "Total Sales")

```


### **3.9 Analyze sales of each product line by gender**
```{r}
Gender_summary <- df %>%
  group_by(Gender, Branch, Product_line) %>%
  summarize(Gender_Sales = sum(Quantity, na.rm = TRUE))

ggplot(Gender_summary, aes(x = Gender, y = Gender_Sales, fill = Product_line)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Sales Distribution by Gender",
       x = "Gender", y = "Total Sales")
```

### **3.10 Analyze sales of each product line by membership status**
```{r}
#group by customer type
Member_summary <- df %>%
  group_by(Customer_type, Branch, Product_line) %>%
  summarize(Member_Sales = sum(Quantity, na.rm = TRUE))

ggplot(Member_summary, aes(x = Customer_type, y = Member_Sales, fill = Product_line)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Sales Distribution by Customer Type",
       x = "Customer Type", y = "Total Sales")

#group by product line
ggplot(Member_summary, aes(x = Product_line, y = Member_Sales, fill = Customer_type)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Sales Distribution by Customer Type",
       x = "Product Line", y = "Total Sales")

```

### **3.11 Quantity of Each Product By City**
```{r}

ggplot(df, aes(x = Product_line, y = Quantity, fill = Product_line)) +
  geom_boxplot() +
  facet_wrap(~ City) +
  theme_minimal() +
  labs(title = "Boxplot of Quantity by Product Line and City",
       x = "Product Line",
       y = "Quantity") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

---

## **4. Classification Model**
##### **Objective**

+ The objective of this project is to predict **customer type** (Normal or Member) using supervised machine learning models.


##### **4.1 Data Preparation**

The dataset was preprocessed to ensure clean and consistent inputs for modeling:

1. **Missing Values**: Removed using `na.omit()`.
2. **Encoding**: Categorical variables like `Gender`, `City`, and `Branch` were converted to numerical codes.
3. **Feature Engineering**: Added `Prod_line_code`, `City_code`, `Branch_code`, and `Cust_type_Code` for better representation.
4. **Redundancy Removal**: Dropped original categorical columns to avoid duplication.
5. **Validation**: Ensured proper formatting using `str()`.

These steps optimized the dataset for machine learning algorithms.

```{r data-summary, message=FALSE, warning=FALSE}
# Load required libraries
library(ggplot2)
library(dplyr)
library(randomForest)
library(caret)
library(e1071)
library(xgboost)
library(lightgbm)
library(rpart)
library(class)

# Inspect the dataset
summary(df)
str(df)

# Check and encode categorical variables
df$Gender <- as.factor(df$Gender)
df$Customer_type <- as.factor(df$Customer_type)
df$Product_line <- as.factor(df$Product_line)
df$City <- as.factor(df$City)
df$Branch <- as.factor(df$Branch)

# Create encoded fields
df <- df %>%
  mutate(
    Gender_code = as.integer(Gender == "Female"),
    Branch_code = as.integer(factor(Branch, levels = c("A", "B", "C"))),
    City_code = as.integer(factor(City, levels = c("Mandalay", "Naypyitaw", "Yangon"))),
    Cust_type_Code = as.integer(Customer_type == "Normal"),
    Prod_line_code = as.integer(factor(Product_line, levels = c(
      "Electronic accessories", "Fashion accessories", "Food and beverages",
      "Health and beauty", "Home and lifestyle", "Sports and travel"
    )))
  )

# Verify the new structure
str(df)

# Remove original categorical columns to avoid redundancy
df <- df %>%
  select(-Gender, -Product_line, -City, -Branch)

# Display a sample of the updated data for verification
head(df)

```


##### **4.2 Customer Type Prediction**

**Data Preparation for Customer Type**

To enhance model robustness with limited data:

1. **Train-Test Split**: Split dataset (80% train, 20% test) using stratified sampling.
2. **Noise Injection**: Added 1% Gaussian noise to numerical features in training data.
3. **Data Augmentation**: Combined original and noise-augmented data to double training size.
4. **Validation**: Ensured consistent target levels and class balance.

These steps improved data variability and model generalization.

```{r customer-type-data-preprocessing, echo=TRUE}
# Split the data for Customer Type prediction
set.seed(123)
cust_type_trainIndex <- createDataPartition(df$Cust_type_Code, p = 0.8, list = FALSE)
data_cust_type_train <- df[cust_type_trainIndex, ]
data_cust_type_test <- df[-cust_type_trainIndex, ]

# Ensure all features are numeric
numeric_features <- sapply(data_cust_type_train, is.numeric)
data_cust_type_train <- data_cust_type_train[, numeric_features]
data_cust_type_test <- data_cust_type_test[, numeric_features]

# Ensure Cust_type_Code is a factor with consistent levels
data_cust_type_train$Cust_type_Code <- as.factor(data_cust_type_train$Cust_type_Code)
data_cust_type_test$Cust_type_Code <- factor(data_cust_type_test$Cust_type_Code, 
                                              levels = levels(data_cust_type_train$Cust_type_Code))

# Noise Injection for Data Augmentation
augment_data_with_noise <- function(data, target_column, noise_level = 0.01) {
  augmented_data <- data
  numeric_columns <- setdiff(names(data), target_column)
  for (col in numeric_columns) {
    if (is.numeric(data[[col]])) {
      noise <- rnorm(n = nrow(data), mean = 0, sd = noise_level * sd(data[[col]]))
      augmented_data[[col]] <- augmented_data[[col]] + noise
    }
  }
  return(augmented_data)
}

# Apply noise injection to training data
data_cust_type_train_noisy <- augment_data_with_noise(data_cust_type_train, "Cust_type_Code")

# Combine original and augmented data
data_cust_type_train <- rbind(data_cust_type_train, data_cust_type_train_noisy)

# Check the distribution of Cust_type_Code after augmentation
table(data_cust_type_train$Cust_type_Code)
table(data_cust_type_test$Cust_type_Code)
```


**Random Forest for Customer Type Prediction**

The Random Forest model was trained with:

1. **Hyperparameter Tuning**: Grid search over `mtry` (2, 3, 4) with 5-fold cross-validation and 500 trees.
2. **Feature Importance**: Key predictors identified using `varImp()`.
3. **Performance Evaluation**: Metrics like Accuracy and F1 Score assessed via confusion matrix.

The model showed balanced performance and valuable feature insights.

```{r rf-customer-type-prediction, echo=TRUE}
RF_CustomerType <- function(data_train, data_test) {
  # Train Random Forest model with hyperparameter tuning
  control <- trainControl(method = "cv", number = 5)
  tune_grid <- expand.grid(mtry = c(2, 3, 4))  # Only include mtry in tuneGrid

  # Train model using caret with limited parameters
  model <- train(
    Cust_type_Code ~ ., data = data_train, method = "rf",
    trControl = control, tuneGrid = tune_grid,
    ntree = 500  # Pass ntree directly
  )

  # Make predictions
  x_test <- data_test[, -which(names(data_test) == "Cust_type_Code")]
  y_test <- data_test$Cust_type_Code
  predictions <- predict(model, x_test)
  predictions <- factor(predictions, levels = levels(y_test))

  # Evaluate performance
  cm <- confusionMatrix(predictions, y_test)

  # Feature Importance
  importance <- varImp(model, scale = FALSE)
  print(importance)

  return(list(model = model, confusion_matrix = cm, feature_importance = importance))
}

customer_type_results_rf <- RF_CustomerType(data_cust_type_train, data_cust_type_test)
customer_type_results_rf$confusion_matrix
```


**Visualization and Feature Importance**

```{r feature-importance, echo=TRUE}
varImpPlot(customer_type_results_rf$model$finalModel, main = "Feature Importance for Customer Type Prediction (Random Forest)")
```


**K-Nearest Neighbors for Customer Type Prediction**

The K-Nearest Neighbors model was trained and evaluated as follows:

1. **Data Standardization**: Both training and test datasets were scaled to ensure feature comparability.
2. **Model Configuration**: Used a fixed value of `k = 5` to determine the nearest neighbors during classification.
3. **Performance Evaluation**:Predictions were made on the test set, and metrics were calculated using a confusion matrix.

The model demonstrated strong Recall, making it ideal for scenarios where sensitivity is critical.

```{r knn-customer-type-prediction, echo=TRUE}
KNN_CustomerType <- function(data_train, data_test, k = 5) {
  # Prepare data
  x_train <- data_train[, -which(names(data_train) == "Cust_type_Code")]
  y_train <- data_train$Cust_type_Code
  x_test <- data_test[, -which(names(data_test) == "Cust_type_Code")]
  y_test <- data_test$Cust_type_Code

  # Standardize features
  x_train <- scale(x_train)
  x_test <- scale(x_test, center = attr(x_train, "scaled:center"), scale = attr(x_train, "scaled:scale"))

  # Make predictions
  predictions <- knn(x_train, x_test, y_train, k = k)

  # Evaluate performance
  cm <- confusionMatrix(predictions, y_test)

  return(list(model = "KNN", confusion_matrix = cm))
}

# Example usage
customer_type_results_knn <- KNN_CustomerType(data_cust_type_train, data_cust_type_test, k = 5)
print(customer_type_results_knn$confusion_matrix)
```

**Decision Tree for Customer Type Prediction** 

The Decision Tree model was trained using the `rpart` package:

1. **Training**: Used Gini index to split nodes and predict `Cust_type_Code`.
2. **Prediction**: Tested on unseen data with `predict()`.
3. **Evaluation**: Metrics like Accuracy and Recall were assessed via confusion matrix.

The model offers high interpretability for transparent decision-making.

```{r dt-customer-type-prediction, echo=TRUE}
DT_CustomerType <- function(data_train, data_test) {
  # Train Decision Tree model
  model <- rpart(Cust_type_Code ~ ., data = data_train, method = "class")
  
  # Make predictions
  x_test <- data_test[, -which(names(data_test) == "Cust_type_Code")]
  y_test <- data_test$Cust_type_Code
  predictions <- predict(model, x_test, type = "class")
  predictions <- factor(predictions, levels = levels(y_test))
  
  # Evaluate performance
  cm <- confusionMatrix(predictions, y_test)
  return(list(model = model, confusion_matrix = cm))
}

# Example of using the function
customer_type_results_dt <- DT_CustomerType(data_cust_type_train, data_cust_type_test)
print(customer_type_results_dt$confusion_matrix)
```

**XGBoost for Customer Type Prediction**

The XGBoost model was trained with:

1. **Training**: Depth 4, learning rate 0.1, and 200 rounds for binary classification.
2. **Prediction**: Classified test data using a 0.5 threshold.
3. **Evaluation**: Assessed metrics via confusion matrix.

XGBoost showed competitive performance on complex data.

```{r xgboost-customer-type-prediction, echo=TRUE}
XGBoost_CustomerType <- function(data_train, data_test) {
  # Prepare data matrices
  x_train <- as.matrix(data_train[, -which(names(data_train) == "Cust_type_Code")])
  y_train <- as.integer(data_train$Cust_type_Code) - 1
  x_test <- as.matrix(data_test[, -which(names(data_test) == "Cust_type_Code")])
  y_test <- as.integer(data_test$Cust_type_Code) - 1

  # Train XGBoost model with hyperparameter tuning
  model <- xgboost(data = x_train, label = y_train, max.depth = 4, eta = 0.1, nround = 200, 
                   objective = "binary:logistic", verbose = 0)

  # Make predictions
  predictions <- predict(model, x_test)
  predictions <- ifelse(predictions > 0.5, 1, 0)
  predictions <- factor(predictions, levels = 0:1)

  # Evaluate performance
  cm <- confusionMatrix(predictions, factor(y_test, levels = 0:1))

  return(list(model = model, confusion_matrix = cm))
}

customer_type_results_xgb <- XGBoost_CustomerType(data_cust_type_train, data_cust_type_test)
customer_type_results_xgb$confusion_matrix
```

**LightGBM for Customer Type Prediction**

The LightGBM model was trained with:

1. **Training**: Learning rate 0.05, max depth 6, 31 leaves, using binary logloss.
2. **Prediction**: Classified test data with a 0.5 threshold.
3. **Evaluation**: Assessed metrics via confusion matrix.

LightGBM showed balanced and reliable performance.

```{r lightgbm-customer-type-prediction, echo=TRUE, warning=FALSE, message=FALSE}
LightGBM_CustomerType <- function(data_train, data_test) {
  # Prepare data matrices
  x_train <- as.matrix(data_train[, -which(names(data_train) == "Cust_type_Code")])
  y_train <- as.integer(data_train$Cust_type_Code) - 1
  x_test <- as.matrix(data_test[, -which(names(data_test) == "Cust_type_Code")])
  y_test <- as.integer(data_test$Cust_type_Code) - 1

  # Train LightGBM model with hyperparameter tuning
  train_data <- lgb.Dataset(data = x_train, label = y_train)
  params <- list(objective = "binary", metric = "binary_logloss", learning_rate = 0.05, 
                 num_leaves = 31, max_depth = 6,verbose = -1)
  
  # Train the LightGBM model
  model <- lgb.train(params, train_data, 200)

  # Make predictions
  predictions <- predict(model, x_test)
  predictions <- ifelse(predictions > 0.5, 1, 0)
  predictions <- factor(predictions, levels = 0:1)

  # Evaluate performance
  cm <- confusionMatrix(predictions, factor(y_test, levels = 0:1))

  return(list(model = model, confusion_matrix = cm))
}

# Call the function and store results
customer_type_results_lgbm <- LightGBM_CustomerType(data_cust_type_train, data_cust_type_test)
customer_type_results_lgbm$confusion_matrix
```


#### **4.3 Results and Discussion**

**Customer Type Prediction Results**

```{r customer-type-results, echo=TRUE}
# Combine all confusion matrices into a table for comparison
model_results <- list(
  "Random Forest" = customer_type_results_rf$confusion_matrix,
  "K-Nearest Neighbors" = customer_type_results_knn$confusion_matrix,
  "Decision Tree" = customer_type_results_dt$confusion_matrix,
  "XGBoost" = customer_type_results_xgb$confusion_matrix,
  "LightGBM" = customer_type_results_lgbm$confusion_matrix
)

# Create a comparison table for key metrics
comparison_table <- data.frame(
  Model = names(model_results),
  Accuracy = round(sapply(model_results, function(x) x$overall["Accuracy"]), 4),
  Precision = round(sapply(model_results, function(x) x$byClass["Pos Pred Value"]), 4),
  Recall = round(sapply(model_results, function(x) x$byClass["Sensitivity"]), 4),
  F1_Score = round(sapply(model_results, function(x) {
    precision <- x$byClass["Pos Pred Value"]
    recall <- x$byClass["Sensitivity"]
    if (!is.na(precision) && !is.na(recall) && (precision + recall) > 0) {
      2 * (precision * recall) / (precision + recall)
    } else {
      NA
    }
  }), 4),
  Specificity = round(sapply(model_results, function(x) x$byClass["Specificity"]), 4)
)

# Print the comparison table
print(comparison_table)

# Visualize comparison metrics
library(reshape2)
library(ggplot2)

comparison_table_melted <- melt(comparison_table, id.vars = "Model")

# Improved visualization with clear labels and distinct colors
ggplot(comparison_table_melted, aes(x = Model, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
  labs(title = "Model Performance Metrics", x = "Model", y = "Metric Value") +
  scale_fill_brewer(palette = "Set3", name = "Metrics") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "top",
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold")
  )
```


### **4.4 Model Comparison and Recommendation**

##### Best Model: **K-Nearest Neighbors**
- **Accuracy**: 0.5202 (competitive among models).
- **F1 Score**: 0.5274 (highest among all models).
- **Recall**: 0.5521 (best among all models), **Precision**: 0.5048.
- **Conclusion**: Superior Recall and F1 Score make it the most suitable model for overall performance.

##### Runner-Up: **Random Forest**
- **Accuracy**: 0.5202, **F1 Score**: 0.5226, **Recall**: 0.5417 (best among all models).
- **Conclusion**: Balanced performance, making it a strong alternative..

##### Other Models:
- **LightGBM**: Reliable performance with Accuracy of 0.5101 and F1 Score of 0.5126.
- **XGBoost**: Moderate performance (F1 Score: 0.4767).
- **Decision Tree**: Accuracy 0.5152, but lowest F1 Score (0.4074).

##### Recommendation:
- **Primary**: Use **K-Nearest Neighbors** for its superior F1 Score and Recall, ensuring the best model for tasks requiring sensitivity.
- **Secondary**: Consider **Random Forest** for its balanced and robust alternative.
- **Alternative**: Use **LightGBM** for consistent results in scenarios requiring trade-offs.

##### **4.5 Conclusion**

The objective of predicting **customer type** (Normal or Member) was approached using multiple supervised learning models. However, the overall model performance remained moderate, with the highest Accuracy at only 52.02% (K-Nearest Neighbors). Several factors may have contributed to this:

1. **Data Imbalance or Insufficiency**: A relatively small dataset of 994 samples may not adequately represent the complexity of the problem, limiting model generalization.
2. **Feature Limitations**: Key predictors might be missing, and existing features might not fully capture the variability of customer types.
3. **Noise in Data**: Transaction and demographic data may contain inconsistencies or subtle correlations that are difficult for models to capture.

**Recommendations:**

1. **Expand the Dataset**:
   - Collect more data to improve model training and generalization.
   - Ensure balanced representation of customer types.

2. **Feature Engineering**:
   - Investigate additional features, such as purchase frequency or membership duration.
   - Perform advanced feature selection or transformation to capture hidden patterns.

3. **Explore Advanced Models**:
   - Use ensemble techniques or neural networks for potentially better performance on complex datasets.

4. **Data Quality Improvements**:
   - Address potential noise and inconsistencies in the dataset.
   - Conduct exploratory analysis to better understand the data distributions.

While Random Forest remains the most balanced choice, further efforts in data collection and feature refinement are essential for achieving higher predictive accuracy.

---

## **5. Regression Model**

##### **Objective**

+ The objective of this project is to predict the **total sales** amount of a single transaction.

**Splite dataset based on "Tax"**

```{r}
# Split the data into a training set and a test set based on "Tax"
# Assuming "Tax" is the target variable
train_sales_index <- createDataPartition(df$Tax, p = 0.7, list = FALSE)
# Use the target variable column instead of the entire dataframe

# Create training and testing sets using the train_index
train_sales <- df[train_sales_index, ]
test_sales <- df[-train_sales_index, ]

# separate X and y that extract them from train_data and test_data
X_trains <- train_sales[, -which(names(train_sales) == "Tax")] # Exclude target variable
y_trains <- train_sales$Tax
X_tests <- test_sales[, -which(names(test_sales) == "Tax")] # Exclude target variable
y_tests <- test_sales$Tax

head(X_trains)
nrow(X_trains)
head(y_trains)
head(X_tests)
nrow(X_tests)
head(y_tests)
```


**Linear Regression**
```{r}
# Linear Regression function
LR <- function(data_train, data_test, target_train, target_test) {
  # Build the Linear Regression model
  model <- lm(target_train ~ ., data = data.frame(data_train, target_train))

  # Make predictions
  predictions <- predict(model, data_test)

  # Compute Mean Squared Error (MSE) for evaluation
  mse <- mean((predictions - target_test)^2)

  # Compute R-squared value for evaluation
  rsq <- summary(model)$r.squared

  # Return MSE and R-squared value
  return(list(MSE = mse, R_squared = rsq))
}

LR_result <- LR(X_trains, X_tests, y_trains, y_tests)
print(LR_result)
```


**Gradient Boosting Regression**

```{r}
# Gradient Boosting Regression function
GBR <- function(data_train, data_test, target_train, target_test) {
  
  # Ensure all columns are numeric
  data_train[] <- lapply(data_train, function(x) if(is.factor(x) || is.character(x)) as.numeric(as.factor(x)) else as.numeric(x))
  data_test[] <- lapply(data_test, function(x) if(is.factor(x) || is.character(x)) as.numeric(as.factor(x)) else as.numeric(x))

  # Convert to matrices
  data_train <- data.matrix(data_train)
  data_test <- data.matrix(data_test)

  # Ensure target variables are numeric
  target_train <- as.numeric(target_train)
  target_test <- as.numeric(target_test)

  # Prepare the data for xgboost (convert to matrix format)
  train_matrix <- xgb.DMatrix(data = as.matrix(data_train), label = target_train)
  test_matrix <- xgb.DMatrix(data = as.matrix(data_test), label = target_test)

  # Set up parameters for gradient boosting model
  params <- list(
    objective = "reg:squarederror",  # For regression task (squared error)
    eval_metric = "rmse",            # Root Mean Squared Error
    max_depth = 6,                   # Maximum depth of the tree
    eta = 0.1,                       # Learning rate
    nthread = 2                      # Number of threads to use
  )

  # Train the Gradient Boosting model
  model <- xgb.train(params = params,
                     data = train_matrix,
                     nrounds = 100)  # Number of boosting rounds

  # Make predictions
  predictions <- predict(model, test_matrix)

  # Compute Mean Squared Error (MSE) for evaluation
  mse <- mean((predictions - target_test)^2)

  # Compute R-squared value for evaluation
  rsq <- 1 - sum((predictions - target_test)^2) / sum((target_test - mean(target_test))^2)

  # Return MSE and R-squared value
  return(list(MSE = mse, R_squared = rsq))
}


GBR_result <- GBR(X_trains, X_tests, y_trains, y_tests)
print(GBR_result)
```


**Random Forest Regression**
```{r}
# Random Forest Regression function
RFR <- function(data_train, data_test, target_train, target_test) {
  # Build the Random Forest Regression model
  model <- randomForest(x = data_train, y = target_train)

  # Make predictions
  predictions <- predict(model, data_test)

  # Compute Mean Squared Error (MSE) for evaluation
  mse <- mean((predictions - target_test)^2)

  # Compute R-squared value for evaluation
  rsq <- 1 - sum((predictions - target_test)^2) / sum((target_test - mean(target_test))^2)

  # Return MSE and R-squared value
  return(list(MSE = mse, R_squared = rsq))
}


RFR_result <- RFR(X_trains, X_tests, y_trains, y_tests)
print(RFR_result)
```


**Model Comparison**
```{r}
# Evaluation and Comparison

# Define the Evaluation Function for Regression Models (MSE, R-squared, RMSE)
evaluate_model_regression <- function(mse, rsq) {
  results <- data.frame(
    MSE = mse,
    R_squared = rsq,
    RMSE = sqrt(mse)  # RMSE is the square root of MSE
  )
  return(results)
}

# Linear Regression Model
LR <- function(data_train, data_test, target_train, target_test) {
  # Train the model
  model <- lm(target_train ~ ., data = data.frame(data_train, target_train))

  # Make predictions
  predictions <- predict(model, newdata = data.frame(data_test))

  # Compute Mean Squared Error (MSE) for evaluation
  mse <- mean((predictions - target_test)^2)

  # Compute R-squared value for evaluation
  rsq <- summary(model)$r.squared

  # Return MSE and R-squared
  return(list(MSE = mse, R_squared = rsq))
}

# Gradient Boosting Regression Model
GBR <- function(data_train, data_test, target_train, target_test) {
  
  # Ensure all columns are numeric
  data_train[] <- lapply(data_train, function(x) if(is.factor(x) || is.character(x)) as.numeric(as.factor(x)) else as.numeric(x))
  data_test[] <- lapply(data_test, function(x) if(is.factor(x) || is.character(x)) as.numeric(as.factor(x)) else as.numeric(x))

  # Convert to matrices
  data_train <- data.matrix(data_train)
  data_test <- data.matrix(data_test)

  # Ensure target variables are numeric
  target_train <- as.numeric(target_train)
  target_test <- as.numeric(target_test)
  
  # Convert data to matrix format for xgboost
  train_matrix <- xgb.DMatrix(data = as.matrix(data_train), label = target_train)
  test_matrix <- xgb.DMatrix(data = as.matrix(data_test), label = target_test)

  # Set parameters for gradient boosting model
  params <- list(
    objective = "reg:squarederror",
    eval_metric = "rmse",
    max_depth = 6,
    eta = 0.1,
    nthread = 2
  )

  # Train the model
  model <- xgb.train(params = params, data = train_matrix, nrounds = 100)

  # Make predictions
  predictions <- predict(model, test_matrix)

  # Compute Mean Squared Error (MSE) for evaluation
  mse <- mean((predictions - target_test)^2)

  # Compute R-squared value for evaluation
  rsq <- 1 - sum((predictions - target_test)^2) / sum((target_test - mean(target_test))^2)

  # Return MSE and R-squared
  return(list(MSE = mse, R_squared = rsq))
}

# Random Forest Regression Model
RFR <- function(data_train, data_test, target_train, target_test) {
  # Train the model
  model <- randomForest(x = data_train, y = target_train)

  # Make predictions
  predictions <- predict(model, data_test)

  # Compute Mean Squared Error (MSE) for evaluation
  mse <- mean((predictions - target_test)^2)

  # Compute R-squared value for evaluation
  rsq <- 1 - sum((predictions - target_test)^2) / sum((target_test - mean(target_test))^2)

  # Return MSE and R-squared
  return(list(MSE = mse, R_squared = rsq))
}

# Linear Regression Model Evaluation
LR_result <- LR(X_trains, X_tests, y_trains, y_tests)

# Gradient Boosting Regression Model Evaluation
GBR_result <- GBR(X_trains, X_tests, y_trains, y_tests)

# Random Forest Regression Model Evaluation
RFR_result <- RFR(X_trains, X_tests, y_trains, y_tests)

# Evaluate each model using the evaluation function
LR_eval <- evaluate_model_regression(LR_result$MSE, LR_result$R_squared)
GBR_eval <- evaluate_model_regression(GBR_result$MSE, GBR_result$R_squared)
RFR_eval <- evaluate_model_regression(RFR_result$MSE, RFR_result$R_squared)

# Combine all results for comparison
comparison <- rbind(
  Linear_Regression = LR_eval,
  Gradient_Boosting = GBR_eval,
  Random_Forest = RFR_eval
)

# Print the comparison table
print(comparison)
```

**Key Findings:**

+ Gradient Boosting Regression demonstrated the highest performance with an R² score of 0.995 and the lowest Mean Squared Error (MSE).
+ Random Forest Regression also provided reliable results with an R² score of 0.978.
+ Linear Regression showed moderate performance compared to ensemble models.

---

## **6. Conclusion **

In this project, we successfully applied supervised machine learning techniques to predict supermarket sales trends and classify customer types (Normal or Member). Using a structured dataset from Kaggle, we implemented robust data preprocessing, performed exploratory data analysis (EDA), and built both regression and classification models to derive actionable insights.

This study provided a comprehensive approach to predicting sales trends and classifying customer types using machine learning. The findings offer valuable insights for supermarket managers and decision-makers to better understand purchasing behavior, optimize inventory management, and implement targeted marketing strategies.

---

## **7. Appendix**

+ **youtube:**
+ **rpubs: **
